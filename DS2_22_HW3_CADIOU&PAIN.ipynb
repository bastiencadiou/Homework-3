{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELP\n",
    "\n",
    "https://practicaldatascience.co.uk/machine-learning/how-to-use-category-encoders-to-transform-categorical-variables\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from random import sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded on:   2022-05-12 13:51:50\n"
     ]
    }
   ],
   "source": [
    "random.seed(10) \n",
    "\n",
    "from functions import *\n",
    "# Load data - set index column, decimal point, separator\n",
    "data = pd.read_csv('hw1_devsample.csv', sep=',',\n",
    "                   decimal='.', index_col='SK_ID_CURR')\n",
    "\n",
    "# print time of data being loaded - use strftime\n",
    "print(f'Data loaded on:   {datetime.datetime.now().strftime(format=\"%Y-%m-%d %H:%M:%S\")}')\n",
    "data_xgb = data.copy()\n",
    "\n",
    "data_test = pd.read_csv('hw1_outofsample.csv', sep=',',decimal='.', index_col='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_xgb['TARGET']\n",
    "data_xgb = data_xgb.drop(['MONTH','TIME','DAY','BASE','TARGET'], axis=1)\n",
    "#data_xgb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.drop(['MONTH','TIME','DAY','BASE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred = data_xgb.columns\n",
    "cols_pred_cat = [col for col in cols_pred if data_xgb[col].dtype == 'O']\n",
    "#cols_pred_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_xgb, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test target encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.target_encoder.TargetEncoder(verbose=0, \n",
    "cols=cols_pred_cat,\n",
    "return_df=True, handle_missing='value', \n",
    "handle_unknown='value'\n",
    ")\n",
    "X_train = target_encoder.fit_transform(X_train, y_train)\n",
    "X_test = target_encoder.fit_transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column MEAN_AMTCR_1M_3M_DIV_MEAN_AMTCR_3M_12M includes infinity values.\n",
      "Column MEAN_AMTCR_1M_3M_TYPE_EQ_ACTIVE_DIV_MEAN_AMTCR_3M_12M_TYPE_EQ_ACTIVE includes infinity values.\n",
      "Column MEAN_AMTCR_1M_3M_TYPE_EQ_CLOSED_DIV_MEAN_AMTCR_3M_12M_TYPE_EQ_CLOSED includes infinity values.\n",
      "Column MEAN_AMTCR_OVERDUE_0M_INFM_DIV_MEAN_AMTCR_0M_INFM includes infinity values.\n",
      "Column MEAN_AMTCR_OVERDUE_0M_INFM_TYPE_EQ_ACTIVE_DIV_MEAN_AMTCR_0M_INFM_TYPE_EQ_ACTIVE includes infinity values.\n",
      "Column MEAN_AMTCR_OVERDUE_0M_INFM_DIV_MEAN_AMTCR_0M_INFM includes infinity values.\n",
      "Column MEAN_AMTCR_OVERDUE_0M_12M_DIV_MEAN_AMTCR_0M_12M includes infinity values.\n",
      "Column MEAN_AMTCR_OVERDUE_0M_INFM_TYPE_EQ_ACTIVE_DIV_MEAN_AMTCR_0M_INFM_TYPE_EQ_ACTIVE includes infinity values.\n",
      "Column MEAN_AMTCR_OVERDUE_0M_12M_TYPE_EQ_ACTIVE_DIV_MEAN_AMTCR_0M_12M_TYPE_EQ_ACTIVE includes infinity values.\n"
     ]
    }
   ],
   "source": [
    "# find columns with infinity values\n",
    "cols_with_inf = []\n",
    "for col in X_train.columns:\n",
    "    if np.any(np.isinf(X_train[col])):\n",
    "        cols_with_inf.append(col)\n",
    "        print(f'Column {col} includes infinity values.')\n",
    "\n",
    "# find columns with negative infinity values\n",
    "cols_with_neginf = []\n",
    "for col in X_train.columns:\n",
    "    if np.any(np.isneginf(X_train[col])):\n",
    "        cols_with_neginf.append(col)\n",
    "        print(f'Column {col} includes negative infinity values.')\n",
    "\n",
    "for col in cols_with_inf:\n",
    "    X_train[col].replace(np.inf, 9999999, inplace = True)\n",
    "\n",
    "    # find columns with infinity values\n",
    "cols_with_inf = []\n",
    "for col in X_test.columns:\n",
    "    if np.any(np.isinf(X_test[col])):\n",
    "        cols_with_inf.append(col)\n",
    "        print(f'Column {col} includes infinity values.')\n",
    "\n",
    "# find columns with negative infinity values\n",
    "cols_with_neginf = []\n",
    "for col in X_test.columns:\n",
    "    if np.any(np.isneginf(X_test[col])):\n",
    "        cols_with_neginf.append(col)\n",
    "        print(f'Column {col} includes negative infinity values.')\n",
    "\n",
    "for col in cols_with_inf:\n",
    "    X_test[col].replace(np.inf, 9999999, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.target_encoder.TargetEncoder( \n",
    "cols=cols_pred_cat,\n",
    "return_df=True, handle_missing='value', \n",
    "handle_unknown='value'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(objective='binary:logistic', booster='gbtree', \n",
    "                        eval_metric = 'auc',tree_method = 'auto', seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('Mean_Target_Encoding', target_encoder),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halving Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'Mean_Target_Encoding__smoothing': [0.5, 1.0, 1.5,2.0],\n",
    "    'model__max_depth': [2, 3, 4, 5, 6, 8],\n",
    "    'model__eta' : [0.2,0.3,0.4,0,0.5,0.8,1.0],\n",
    "    'model__gamma': [0,1,2,3,4,5],\n",
    "    'model__subsample' : [0.1,0.3,0.6,0.8,1],\n",
    "    'model__lambda' : [0.5,1,2],\n",
    "    'model__min_child_weight' : [0.5,1,2,3],\n",
    "    'model__max_delta_step' : [0,1,2,3,4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply pipeline to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FACTOR = 3\n",
    "#MAX_RESOURCE_DIVISOR = 2\n",
    "#n_samples = len(X_train)\n",
    "#min_ressources = int(n_samples/MAX_RESOURCE_DIVISOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search = HalvingRandomSearchCV(pipe, param_grid, aggressive_elimination=True,resource='n_samples',\n",
    "#                                min_resources=min_ressources,factor=FACTOR,).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232ed0160155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = HalvingRandomSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_grid,\n",
    "    #aggressive_elimination=True,\n",
    "    factor=3,\n",
    "    n_candidates=50,\n",
    "    resource='n_samples',\n",
    "    min_resources='exhaust',\n",
    "    cv=4,\n",
    "    scoring='roc_auc',\n",
    "    error_score=0,\n",
    "    n_jobs=-1\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(hrs.cv_results_)\n",
    "results[\"params_str\"] = results.params.apply(str)\n",
    "results.drop_duplicates(subset=(\"params_str\", \"iter\"), inplace=True)\n",
    "mean_scores = results.pivot(\n",
    "    index=\"iter\", columns=\"params_str\", values=\"mean_test_score\"\n",
    ")\n",
    "ax = mean_scores.plot(legend=False, alpha=0.6)\n",
    "\n",
    "labels = [\n",
    "    f\"iter={i}\\nn_samples={hrs.n_resources_[i]}\\nn_candidates={hrs.n_candidates_[i]}\"\n",
    "    for i in range(hrs.n_iterations_)\n",
    "]\n",
    "\n",
    "ax.set_xticks(range(hrs.n_iterations_))\n",
    "ax.set_xticklabels(labels, rotation=45, multialignment=\"left\")\n",
    "ax.set_title(\"Scores of candidates over iterations\")\n",
    "ax.set_ylabel(\"mean test score\", fontsize=15)\n",
    "ax.set_xlabel(\"iterations\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(hrs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = hrs.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC',roc_auc_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = hrs.predict_proba(data_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saving = pd.DataFrame({'SK_ID_CURR' : data_test.index ,'prediction' : prediction})\n",
    "data_saving.to_csv('DS2_22_HW3_CADIOU&PAIN.csv',index=False,sep=',')\n",
    "data_saving.info()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e593ac106456af50ce7af38f9671c411b49d6cd90f9b885e167f0f594e09038c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
